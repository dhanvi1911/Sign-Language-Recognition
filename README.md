Sign Language Recognition

The project aims at building a machine learning model that will be able to classify the various hand gestures used for fingerspelling in sign language. In this user independent model, classification machine learning algorithms are trained using a set of image data. For the image dataset, depth images are used, which gave better results than some of the previous literatures, owing to the reduced pre-processing time. The machine learning algorithm applied on the datasets is Convolutional Neural Network (CNN).

Scanning & Recognition of Gestures
 
Fig 1.0: Recognition of Letter A 

 ![image](https://github.com/dhanvi1911/Sign-Language-Recognition/assets/67651344/d0444472-9dee-46ff-8880-386903d392a6)

Fig 2.0: Recognition of Letter B
![Uploading image.pngâ€¦]()

 
Fig 3.0: Recognition of Letter C


 
Fig 4.0: Recognition of Letter D

 
Fig 5.0: Recognition of Letter F

 
Fig 6.0: Recognition of Letter L

 
Fig 7.0: Recognition of Letter O

 
Fig 8.0: Recognition of Letter P

 
Fig 9.0: Recognition of Letter R

 
Fig 10.0: Recognition of Letter V

 
Fig 11.0: Recognition of Letter W

 
Fig 12.0: Recognition of Letter Y





Scanning Sentence


 
Fig 13.0: Scanning the Letter C to form the word CAR

 
Fig 14.0: Scanning the Letter A to form the word CAR
 
Fig 15.0: Scanning the Letter R to form the word CAR
	

Exporting to File


 
Fig 16.0: Saving the scanned word CAR

 
Fig 17.0: Exporting the file containing the scanned word CAR


 
Fig 18.0: Viewing the Gestures saved at the time of scanning the word

 
Fig 19.0: Exporting the text file to the system

 
Fig 20.0: File saved Successfully











